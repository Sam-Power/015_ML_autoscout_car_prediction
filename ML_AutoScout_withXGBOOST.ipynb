{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import XGBRegressor, XGBClassifier,XGBRFRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error, mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('autoscout_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('emission_class',axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('price', axis=1)\n",
    "y = df['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "xgb_model = XGBRegressor().fit(X_train, y_train)\n",
    "y_pred = xgb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_metrics(actual, pred):\n",
    "    mae = mean_absolute_error(actual, pred)\n",
    "    mse = mean_squared_error(actual, pred)\n",
    "    rmse = np.sqrt(mean_squared_error(actual, pred))\n",
    "    score = r2_score(actual, pred)\n",
    "    return print(\"r2_score:\", score, \"\\n\",\"mae:\", mae, \"\\n\",\"mse:\",mse, \"\\n\",\"rmse:\",rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_score: 0.9567880886181679 \n",
      " mae: 922.0930080701359 \n",
      " mse: 2345111.313088822 \n",
      " rmse: 1531.37562769192\n"
     ]
    }
   ],
   "source": [
    "eval_metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 81 candidates, totalling 243 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed: 17.2min\n",
      "[Parallel(n_jobs=-1)]: Done 243 out of 243 | elapsed: 29.1min finished\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBRegressor()\n",
    "xgb_params = {\"n_estimators\": [50, 100, 300], \"subsample\":[0.5,0.8,1], \"max_depth\":[3,5,7], \"learning_rate\":[0.1,0.01,0.3]}\n",
    "xgb_cv_model = GridSearchCV(xgb, xgb_params, cv = 3, n_jobs = -1, verbose = 2).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 300, 'subsample': 0.8}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_cv_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_score: 0.9620051131250813 \n",
      " mae: 858.5102278359572 \n",
      " mse: 2061983.2865658381 \n",
      " rmse: 1435.9607538389891\n"
     ]
    }
   ],
   "source": [
    "xgb_tuned = XGBRegressor(learning_rate= 0.1, max_depth= 7, \n",
    "                         n_estimators= 300, \n",
    "                         subsample= 0.8).fit(X_train, y_train)\n",
    "y_pred = xgb_tuned.predict(X_test)\n",
    "eval_metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_score: 0.9622851750556805 \n",
      " mae: 848.7530937769905 \n",
      " mse: 2046784.3198732936 \n",
      " rmse: 1430.658701393625\n"
     ]
    }
   ],
   "source": [
    "xgb_tuned = XGBRegressor(learning_rate= 0.1, max_depth= 7, \n",
    "                         n_estimators= 350, \n",
    "                         subsample= 0.8).fit(X_train, y_train)\n",
    "y_pred = xgb_tuned.predict(X_test)\n",
    "eval_metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_score: 0.962342536667314 \n",
      " mae: 843.5489807128906 \n",
      " mse: 2043671.304038604 \n",
      " rmse: 1429.570321473765\n"
     ]
    }
   ],
   "source": [
    "xgb_tuned = XGBRegressor(learning_rate= 0.1, max_depth= 7, \n",
    "                         n_estimators= 400, \n",
    "                         subsample= 0.8).fit(X_train, y_train)\n",
    "y_pred = xgb_tuned.predict(X_test)\n",
    "eval_metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_score: 0.9624010862449915 \n",
      " mae: 835.339544401696 \n",
      " mse: 2040493.8172624512 \n",
      " rmse: 1428.4585458676954\n"
     ]
    }
   ],
   "source": [
    "xgb_tuned = XGBRegressor(learning_rate= 0.1, max_depth= 7, \n",
    "                         n_estimators= 500, \n",
    "                         subsample= 0.8).fit(X_train, y_train)\n",
    "y_pred = xgb_tuned.predict(X_test)\n",
    "eval_metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_score: 0.9622888724231048 \n",
      " mae: 824.2201009012347 \n",
      " mse: 2046583.6636676758 \n",
      " rmse: 1430.5885724650802\n"
     ]
    }
   ],
   "source": [
    "xgb_tuned = XGBRegressor(learning_rate= 0.1, max_depth= 7, \n",
    "                         n_estimators= 1000, \n",
    "                         subsample= 0.8).fit(X_train, y_train)\n",
    "y_pred = xgb_tuned.predict(X_test)\n",
    "eval_metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_score: 0.9625472110091504 \n",
      " mae: 811.0700786341375 \n",
      " mse: 2032563.623327647 \n",
      " rmse: 1425.6800564389077\n"
     ]
    }
   ],
   "source": [
    "xgb_tuned = XGBRegressor(learning_rate= 0.1, max_depth= 9, \n",
    "                         n_estimators= 500, \n",
    "                         subsample= 0.8).fit(X_train, y_train)\n",
    "y_pred = xgb_tuned.predict(X_test)\n",
    "eval_metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_score: 0.9611094500612094 \n",
      " mae: 806.584771084426 \n",
      " mse: 2110590.9393318016 \n",
      " rmse: 1452.7873000999841\n"
     ]
    }
   ],
   "source": [
    "xgb_tuned = XGBRegressor(learning_rate= 0.1, max_depth= 15, \n",
    "                         n_estimators= 500, \n",
    "                         subsample= 0.8).fit(X_train, y_train)\n",
    "y_pred = xgb_tuned.predict(X_test)\n",
    "eval_metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_score: 0.9610020215538256 \n",
      " mae: 808.0700100846027 \n",
      " mse: 2116421.0866212337 \n",
      " rmse: 1454.7924548268848\n"
     ]
    }
   ],
   "source": [
    "xgb_tuned = XGBRegressor(learning_rate= 0.1, max_depth= 15, \n",
    "                         n_estimators= 1000, \n",
    "                         subsample= 0.8).fit(X_train, y_train)\n",
    "y_pred = xgb_tuned.predict(X_test)\n",
    "eval_metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_score: 0.9621557459131751 \n",
      " mae: 847.3064509252807 \n",
      " mse: 2053808.4420800305 \n",
      " rmse: 1433.1114548701473\n"
     ]
    }
   ],
   "source": [
    "xgb_tuned = XGBRegressor(learning_rate= 0.15, max_depth= 7, \n",
    "                         n_estimators= 300, \n",
    "                         subsample= 0.8).fit(X_train, y_train)\n",
    "y_pred = xgb_tuned.predict(X_test)\n",
    "eval_metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_score: 0.962196987811894 \n",
      " mae: 838.9241248662747 \n",
      " mse: 2051570.2433943893 \n",
      " rmse: 1432.3303541412467\n"
     ]
    }
   ],
   "source": [
    "xgb_tuned = XGBRegressor(learning_rate= 0.2, max_depth= 7, \n",
    "                         n_estimators= 300, \n",
    "                         subsample= 0.8).fit(X_train, y_train)\n",
    "y_pred = xgb_tuned.predict(X_test)\n",
    "eval_metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_score: 0.962230307503898 \n",
      " mae: 829.0428405455009 \n",
      " mse: 2049761.9830289315 \n",
      " rmse: 1431.6989847830903\n"
     ]
    }
   ],
   "source": [
    "xgb_tuned = XGBRegressor(learning_rate= 0.2, max_depth= 7, \n",
    "                         n_estimators= 600, \n",
    "                         subsample= 0.8).fit(X_train, y_train)\n",
    "y_pred = xgb_tuned.predict(X_test)\n",
    "eval_metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_score: 0.962224967446696 \n",
      " mae: 827.8473585885973 \n",
      " mse: 2050051.7880423355 \n",
      " rmse: 1431.8001913822807\n"
     ]
    }
   ],
   "source": [
    "xgb_tuned = XGBRegressor(learning_rate= 0.2, max_depth= 7, \n",
    "                         n_estimators= 700, \n",
    "                         subsample= 0.8).fit(X_train, y_train)\n",
    "y_pred = xgb_tuned.predict(X_test)\n",
    "eval_metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_score: 0.9622279345513421 \n",
      " mae: 826.7533512594712 \n",
      " mse: 2049890.7632125954 \n",
      " rmse: 1431.7439586785745\n"
     ]
    }
   ],
   "source": [
    "xgb_tuned = XGBRegressor(learning_rate= 0.2, max_depth= 7, \n",
    "                         n_estimators= 800, \n",
    "                         subsample= 0.8).fit(X_train, y_train)\n",
    "y_pred = xgb_tuned.predict(X_test)\n",
    "eval_metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_score: 0.9619754701329204 \n",
      " mae: 801.9925435895296 \n",
      " mse: 2063592.0123557253 \n",
      " rmse: 1436.5208012262563\n"
     ]
    }
   ],
   "source": [
    "xgb_tuned = XGBRegressor(learning_rate= 0.1, max_depth= 15, \n",
    "                         n_estimators= 550, \n",
    "                         subsample= 0.9).fit(X_train, y_train)\n",
    "y_pred = xgb_tuned.predict(X_test)\n",
    "eval_metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_score: 0.9609718729053722 \n",
      " mae: 807.9307623628396 \n",
      " mse: 2118057.254388441 \n",
      " rmse: 1455.3546833636262\n"
     ]
    }
   ],
   "source": [
    "xgb_tuned = XGBRegressor(learning_rate= 0.1, max_depth= 16, \n",
    "                         n_estimators= 550, \n",
    "                         subsample= 0.9).fit(X_train, y_train)\n",
    "y_pred = xgb_tuned.predict(X_test)\n",
    "eval_metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_score: 0.9619760349631811 \n",
      " mae: 801.8833740847793 \n",
      " mse: 2063561.3590059418 \n",
      " rmse: 1436.510131884193\n"
     ]
    }
   ],
   "source": [
    "xgb_tuned = XGBRegressor(learning_rate= 0.1, max_depth= 15, \n",
    "                         n_estimators= 590, \n",
    "                         subsample= 0.9).fit(X_train, y_train)\n",
    "y_pred = xgb_tuned.predict(X_test)\n",
    "eval_metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2_score: 0.9630028625641658 \n",
      " mae: 810.9428559116383 \n",
      " mse: 2007835.4041324568 \n",
      " rmse: 1416.9810881350734\n"
     ]
    }
   ],
   "source": [
    "xgb_tuned = XGBRegressor(learning_rate= 0.1, max_depth= 9, \n",
    "                         n_estimators= 650, \n",
    "                         subsample= 0.9).fit(X_train, y_train)\n",
    "y_pred = xgb_tuned.predict(X_test)\n",
    "eval_metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:36:46] WARNING: /Users/travis/build/dmlc/xgboost/src/learner.cc:516: \n",
      "Parameters: { max_features } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "r2_score: 0.9622445410601117 \n",
      " mae: 814.8487237518157 \n",
      " mse: 2048989.5276425679 \n",
      " rmse: 1431.4291905793202\n"
     ]
    }
   ],
   "source": [
    "xgb_tuned = XGBRegressor(learning_rate= 0.1, max_depth= 33, \n",
    "                         n_estimators= 650, max_features= 50,\n",
    "                         subsample= 0.9).fit(X_train, y_train)\n",
    "y_pred = xgb_tuned.predict(X_test)\n",
    "eval_metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_tuned = XGBRegressor(learning_rate= 0.1, max_depth= 33, \n",
    "                         n_estimators= 650, max_features= 50,\n",
    "                         subsample= 0.9).fit(X_train, y_train)\n",
    "y_pred = xgb_tuned.predict(X_test)\n",
    "eval_metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb = XGBRegressor()\n",
    "# xgb_params = {\"n_estimators\": [600, 700], \"subsample\":[0.8,0.9], \"max_depth\":[9,11], \"learning_rate\":[0.1]}\n",
    "# xgb_cv_model = GridSearchCV(xgb, xgb_params, cv = 3, n_jobs = -1, verbose = 2).fit(X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
